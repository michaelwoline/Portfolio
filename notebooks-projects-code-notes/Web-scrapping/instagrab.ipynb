{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Patrik Wikstrom (patrik.wikstrom@qut.edu.au)\n",
    "# Organisation: QUT Digital Media Research Centre 2017\n",
    "# Version: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the_item = \"catchoftheday\"\n",
    "the_item = \"maisonmargiela\"\n",
    "max_scrape = 150\n",
    "\n",
    "insta_path = \"explore/tags/\"\n",
    "prefix = \"photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from string import ascii_letters, digits, punctuation, printable\n",
    "from IPython.display import Image, display, HTML\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import copy\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_photos_maisonmargiela\n",
      "data/media\n"
     ]
    }
   ],
   "source": [
    "# Create folders as necessary\n",
    "data_path = \"data/data\"  + \"_\" + prefix + \"_\" + the_item\n",
    "media_path = \"data/media\"\n",
    "\n",
    "print(data_path)\n",
    "print(media_path)\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"data\")\n",
    "    print(\"made new data folder\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"data/media\")\n",
    "    print(\"made new media folder\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_path)\n",
    "    print(\"made new project folder\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new scrape. No saved posts found.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f = open(data_path+\"/metadata.json\",\"r\")\n",
    "    the_posts = json.load(f)\n",
    "    f.close()\n",
    "    print(\"found\",len(the_posts),\"saved posts.\")\n",
    "except:\n",
    "    the_posts = {}\n",
    "    print(\"This is a new scrape. No saved posts found.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(\"config.json\",\"r\")\n",
    "except:\n",
    "    f = open(\"default-config.json\",\"r\")\n",
    "\n",
    "conf = json.load(f)\n",
    "f.close()\n",
    "if not the_item in conf:\n",
    "    conf[the_item] = conf[\"default\"]\n",
    "    f = open(\"config.json\",\"w\")\n",
    "    json.dump(conf,f)\n",
    "    f.close()\n",
    "    print(\"Updated the config file.\")\n",
    "deets = conf[the_item]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getcwd() in os.get_exec_path():\n",
    "    print('adding path')\n",
    "    if platform.system() == \"Windows\":\n",
    "        os.environ[\"PATH\"] = os.environ[\"PATH\"] + \";\" + os.getcwd()\n",
    "    else:\n",
    "        os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + os.getcwd()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.instagram.com/\"+insta_path+the_item+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#maisonmargiela â€¢ Instagram photos and videos\n"
     ]
    }
   ],
   "source": [
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send key strokes to scroll down the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is only one page\n"
     ]
    }
   ],
   "source": [
    "# first of all click on the \"Load more\" button\n",
    "\n",
    "# Instagram uses different class names for the \"Load more\" button, so it's necessary to check for more than one.\n",
    "load_more_codes = [\"_8imhp\",\"_oidfu\"]\n",
    "\n",
    "found_it = False\n",
    "\n",
    "for load_more_code in load_more_codes:\n",
    "    if not found_it:\n",
    "        try:\n",
    "            some_element = driver.find_element_by_class_name(load_more_code)\n",
    "            some_element.click()\n",
    "            found_it = True\n",
    "            print(load_more_code)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if not found_it:\n",
    "    print(\"there is only one page\")\n",
    "    some_element = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 | 48 | 69 | 81 | 93 | 105 | 117 | 129 | 141 | 153 | overlap: 0\n"
     ]
    }
   ],
   "source": [
    "# then press space over an over again for a while\n",
    "last_how_many = -1\n",
    "how_many = 0\n",
    "overlap = set()\n",
    "all_links = []\n",
    "\n",
    "# why nine? there are 9 recurring top posts before you get into the recent posts\n",
    "while last_how_many<how_many and how_many<max_scrape and len(overlap)<=9:\n",
    "    \n",
    "    # send a key stroke to the page to scroll down\n",
    "    some_element = driver.find_element_by_tag_name(\"body\")\n",
    "    last_how_many = how_many\n",
    "    for i in range(3):\n",
    "        some_element.send_keys(\" \")\n",
    "        sleep(0.5)\n",
    "        \n",
    "    # check if the posts on the page have already been scraped\n",
    "#     all_links = [u.get_attribute(\"href\").split(\"/\")[4] for u in driver.find_elements_by_class_name(\"_mck9w._gvoze._f2mse\")]\n",
    "    all_links = [u.find_elements_by_xpath(\"./*\")[0].get_attribute(\"href\").split(\"/\")[4] for u in driver.find_elements_by_class_name(\"_mck9w._gvoze._f2mse\")]\n",
    "    overlap = set(the_posts.keys()).intersection(set(all_links))\n",
    "\n",
    "    how_many = len(driver.find_elements_by_class_name(\"_mck9w._gvoze._f2mse\"))\n",
    "    print(how_many,end=\" | \",flush=True)\n",
    "print(\"overlap:\",len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "# print the number of links/codes found in the page and save the list in a temporary file in case everything breaks down.\n",
    "print(len(all_links))\n",
    "f = open(data_path+\"/temp_links.json\",\"w\")\n",
    "json.dump(all_links,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape post pages + download media objects (photos or videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixit(ss):\n",
    "    return \"\".join([s for s in ss if s in ascii_letters+digits]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clstr(ss):\n",
    "    return \"\".join([s for s in ss if s in printable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkup(a_list,ss):\n",
    "    found_it = False\n",
    "    for a in a_list:\n",
    "        if a in ss:\n",
    "            found_it = True\n",
    "    return found_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(ss):\n",
    "    ss = ss.replace(\"\\n\",\" \")\n",
    "    plist = ss.split(\" \")\n",
    "    tags = list(p for p in plist if len(p)>0 and p[0]==\"#\")\n",
    "    tt = []\n",
    "    for t in tags:\n",
    "        tt += t.split(\"#\")\n",
    "    return list(set(list(fixit(t) for t in tt if len(t)>0)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_object(code):\n",
    "    if not os.path.isfile(media_path+\"/\"+the_posts[code].get(\"the_fname\",\"nofile.ppp\")):\n",
    "        try:\n",
    "            a_media_object = requests.get(the_posts[code][\"object_url\"],timeout=2)\n",
    "            with open(media_path+\"/\"+the_posts[code][\"the_fname\"], \"wb\") as f:\n",
    "                f.write(a_media_object.content)\n",
    "            print(\".\",end=\"\",flush=True)\n",
    "        except:\n",
    "            print(\"x\",end=\"\",flush=True)\n",
    "    else:\n",
    "        print(\"_\",end=\"\",flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape new post pages + download media objects (photos or videos)\n",
    "def scrape_single_code(a_code,sleeper=1):\n",
    "    from ast import literal_eval\n",
    "    good_stuff = None\n",
    "    all_fine = True\n",
    "    try:\n",
    "        tt = requests.get(\"https://www.instagram.com/p/\"+a_code,timeout=2)\n",
    "        tt_soup = BeautifulSoup(tt.text, \"lxml\")\n",
    "        sleeper = 1\n",
    "    except:\n",
    "        all_fine = False\n",
    "        print(\"$\",end=\"\",flush=True)\n",
    "        sleep(sleeper)\n",
    "    \n",
    "    if all_fine:\n",
    "        # find all the javascript tags in the code\n",
    "        all_texts = [u.get_text() for u in tt_soup.find_all(\"script\")]\n",
    "\n",
    "        # extract the one that starts with this particular string\n",
    "        all_texts = [at for at in all_texts if \"window._sharedData\" in at[:50]][0]\n",
    "\n",
    "        # fix the JavaScript syntax so that it can be transformed to Python code\n",
    "        all_texts = all_texts.replace(\"window._sharedData\",\"\")\n",
    "        all_texts = all_texts.replace(\"true\",\"True\")\n",
    "        all_texts = all_texts.replace(\"false\",\"False\")\n",
    "        all_texts = all_texts.replace(\"null\",\"None\")\n",
    "        \n",
    "\n",
    "        # extract the dict from the code and reach for the good stuff\n",
    "        stuff = literal_eval(all_texts[3:-1])\n",
    "        try:\n",
    "            good_stuff = copy(stuff[\"entry_data\"][\"PostPage\"][0][\"graphql\"][\"shortcode_media\"])\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "        # add some extra to the dict\n",
    "        good_stuff[\"scrape_ts\"] = str(datetime.now())[:19]\n",
    "        good_stuff[\"caption_tags\"] = extract_hashtags(good_stuff.get(\"caption\",\"\"))\n",
    "        \n",
    "        \n",
    "        if good_stuff[\"is_video\"]:\n",
    "            good_stuff[\"object_url\"] = good_stuff[\"video_url\"]\n",
    "            good_stuff[\"the_fname\"] = a_code + \".mp4\"\n",
    "        else:\n",
    "            good_stuff[\"object_url\"] = good_stuff[\"display_resources\"][-1]['src']\n",
    "            good_stuff[\"the_fname\"] = a_code + \".jpg\"\n",
    "\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "    return good_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape post pages for many codes\n",
    "def scrape_codes(some_codes):\n",
    "    new_stuff = {}\n",
    "    sleeptime=1\n",
    "    cc = 0\n",
    "    for a_code in some_codes:\n",
    "        cc += 1\n",
    "        if cc % 50==0: print(len(new_stuff))\n",
    "        new_stuff[a_code] = copy(scrape_single_code(a_code,sleeptime))\n",
    "        if new_stuff[a_code]==None:\n",
    "            del new_stuff[a_code]\n",
    "            sleeptime += sleeptime\n",
    "        else:\n",
    "            sleeptime = 10\n",
    "    return copy(new_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new stuff to the posts storage\n",
    "def update_post_storage(new_stuff):\n",
    "    cc = 0\n",
    "    for code in new_stuff:\n",
    "        cc += 1\n",
    "        if cc % 50 == 0: print()\n",
    "        if not code in the_posts:\n",
    "            the_posts[code] = copy(new_stuff[code])\n",
    "        if not \"activity\" in the_posts[code]:\n",
    "            the_posts[code][\"activity\"] = []\n",
    "        \n",
    "        tss = [ts[\"scrape_ts\"] for ts in the_posts[code][\"activity\"]]\n",
    "    \n",
    "        if not new_stuff[code][\"scrape_ts\"] in tss:\n",
    "            the_posts[code][\"activity\"] += [{\"scrape_ts\":new_stuff[code][\"scrape_ts\"],\n",
    "                                         \"comments\":new_stuff[code][\"edge_media_to_comment\"],\n",
    "                                         \"likes\":new_stuff[code][\"edge_media_preview_like\"],\n",
    "                                         \"video_views\":new_stuff[code].get(\"video_views\",\"not_a_video\")}]\n",
    "            print(len(the_posts[code][\"activity\"]),end=\"\",flush=True)\n",
    "        else:\n",
    "            # update everything but keep the activity record intact\n",
    "#            for u in new_stuff[code]:\n",
    "#                if u != 'activity':\n",
    "#                    the_posts[code][u] = new_stuff[code][u]\n",
    "            print(\"-\",end=\"\",flush=True)\n",
    "    print(\"\\nPosts in storage:\",len(the_posts))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................48\n",
      "..................................................98\n",
      "...........................................$.\n",
      "142\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-63dd00e3184c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_links\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe_posts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mupdate_post_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-615f64174b4c>\u001b[0m in \u001b[0;36mupdate_post_storage\u001b[0;34m(new_stuff)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_stuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scrape_ts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             the_posts[code][\"activity\"] += [{\"scrape_ts\":new_stuff[code][\"scrape_ts\"],\n\u001b[0;32m---> 16\u001b[0;31m                                          \u001b[0;34m\"comments\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnew_stuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                                          \u001b[0;34m\"likes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnew_stuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"likes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                          \"video_views\":new_stuff[code].get(\"video_views\",\"not_a_video\")}]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'comments'"
     ]
    }
   ],
   "source": [
    "# scrape new post pages (not the photo itself) and add to storage\n",
    "ns = scrape_codes([u for u in all_links if not u in the_posts])\n",
    "print(\"\\n\"+str(len(ns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111111111111111111111111111111111111111111111111\n",
      "11111111111111111111111111111111111111111111111111\n",
      "1111111111111111111111111111111111111111111\n",
      "Posts in storage: 142\n"
     ]
    }
   ],
   "source": [
    "update_post_storage(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__typename': 'GraphImage',\n",
       " 'activity': [{'comments': {'count': 0,\n",
       "    'edges': [],\n",
       "    'page_info': {'end_cursor': None, 'has_next_page': False}},\n",
       "   'likes': {'count': 33,\n",
       "    'edges': [{'node': {'id': '532332428',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/16464547_1728674983824878_2929309378253160448_a.jpg',\n",
       "       'username': 'litdiesel'}},\n",
       "     {'node': {'id': '28739430',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/24177785_547952192264041_7578952999087636480_n.jpg',\n",
       "       'username': 'lucaszach2017'}},\n",
       "     {'node': {'id': '185516426',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/15802297_215461365580242_3610073806476935168_a.jpg',\n",
       "       'username': '9.13.80'}},\n",
       "     {'node': {'id': '5630298362',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/24126278_147560436005310_5267357572670685184_n.jpg',\n",
       "       'username': 'mich_much_fashion'}},\n",
       "     {'node': {'id': '1444304761',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/12816862_209683682733296_1144168546_a.jpg',\n",
       "       'username': 'yuk_da'}},\n",
       "     {'node': {'id': '233786285',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22638756_1391334994297055_4112018035835928576_n.jpg',\n",
       "       'username': '8810_h2o'}},\n",
       "     {'node': {'id': '1013199591',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22802390_1565108160217514_7058394768014835712_n.jpg',\n",
       "       'username': 'eurotrash95'}},\n",
       "     {'node': {'id': '471601722',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/13743357_1629151524081875_1982021818_a.jpg',\n",
       "       'username': 'danielgregorynatale'}},\n",
       "     {'node': {'id': '5526101580',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/20968449_1593371430730112_4418553850366001152_a.jpg',\n",
       "       'username': 'backside.shop'}},\n",
       "     {'node': {'id': '3044101263',\n",
       "       'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22426784_1892529090763817_6637776770902786048_n.jpg',\n",
       "       'username': 'than_nhan_1510'}}]},\n",
       "   'scrape_ts': '2017-11-28 15:20:44',\n",
       "   'video_views': 'not_a_video'}],\n",
       " 'caption_is_edited': False,\n",
       " 'caption_tags': [],\n",
       " 'comments_disabled': False,\n",
       " 'dimensions': {'height': 1080, 'width': 1080},\n",
       " 'display_resources': [{'config_height': 640,\n",
       "   'config_width': 640,\n",
       "   'src': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-15/s640x640/sh0.08/e35/24126550_307697142970254_2459485504198934528_n.jpg'},\n",
       "  {'config_height': 750,\n",
       "   'config_width': 750,\n",
       "   'src': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-15/s750x750/sh0.08/e35/24126550_307697142970254_2459485504198934528_n.jpg'},\n",
       "  {'config_height': 1080,\n",
       "   'config_width': 1080,\n",
       "   'src': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-15/e35/24126550_307697142970254_2459485504198934528_n.jpg'}],\n",
       " 'display_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-15/e35/24126550_307697142970254_2459485504198934528_n.jpg',\n",
       " 'edge_media_preview_like': {'count': 33,\n",
       "  'edges': [{'node': {'id': '532332428',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/16464547_1728674983824878_2929309378253160448_a.jpg',\n",
       "     'username': 'litdiesel'}},\n",
       "   {'node': {'id': '28739430',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/24177785_547952192264041_7578952999087636480_n.jpg',\n",
       "     'username': 'lucaszach2017'}},\n",
       "   {'node': {'id': '185516426',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/15802297_215461365580242_3610073806476935168_a.jpg',\n",
       "     'username': '9.13.80'}},\n",
       "   {'node': {'id': '5630298362',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/24126278_147560436005310_5267357572670685184_n.jpg',\n",
       "     'username': 'mich_much_fashion'}},\n",
       "   {'node': {'id': '1444304761',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/12816862_209683682733296_1144168546_a.jpg',\n",
       "     'username': 'yuk_da'}},\n",
       "   {'node': {'id': '233786285',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22638756_1391334994297055_4112018035835928576_n.jpg',\n",
       "     'username': '8810_h2o'}},\n",
       "   {'node': {'id': '1013199591',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22802390_1565108160217514_7058394768014835712_n.jpg',\n",
       "     'username': 'eurotrash95'}},\n",
       "   {'node': {'id': '471601722',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/13743357_1629151524081875_1982021818_a.jpg',\n",
       "     'username': 'danielgregorynatale'}},\n",
       "   {'node': {'id': '5526101580',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/20968449_1593371430730112_4418553850366001152_a.jpg',\n",
       "     'username': 'backside.shop'}},\n",
       "   {'node': {'id': '3044101263',\n",
       "     'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/22426784_1892529090763817_6637776770902786048_n.jpg',\n",
       "     'username': 'than_nhan_1510'}}]},\n",
       " 'edge_media_to_caption': {'edges': [{'node': {'text': '@dominateofficial \"Story\"\\n\\nFW \\nSTART!\\n\\n#dominate \\n#acnestudios#acoldwall#adidasoriginals#alyx#ambush#amiright #commedesgarcons#enfantsrichesdeprimes#faithconnexion#fearofgod#geodesign#tisci#haiderackermann#hoodbyair#maisonmargiela#marceloburlon#misbhv#marchenoir#offwhite#virgilabloh#placesplusfaces#rafsimons#readymade#rhude#rickowens#thombrowne'}}]},\n",
       " 'edge_media_to_comment': {'count': 0,\n",
       "  'edges': [],\n",
       "  'page_info': {'end_cursor': None, 'has_next_page': False}},\n",
       " 'edge_media_to_sponsor_user': {'edges': []},\n",
       " 'edge_media_to_tagged_user': {'edges': []},\n",
       " 'edge_web_media_to_related_media': {'edges': []},\n",
       " 'gating_info': None,\n",
       " 'id': '1658031254089758673',\n",
       " 'is_ad': False,\n",
       " 'is_video': False,\n",
       " 'location': None,\n",
       " 'media_preview': 'ACoq6GSTZjjOaZ5/tSXHb8aqs4UgEgE9MnrQBb+0e1J9o9qqeYuduRn0zzTqALiTbzjGKmqnB978KuUAVrjtXNTwyqxZgSCSem4Yz7dPyrpbjt+NVdo7cfQ0WuBzyvj7/wAw7MOo/H+lXFvHUhVKuPVuD/ketaTRK3UA/UCmiAL90KvuFwfzzSsO5atSScng45/ycVeqnb/e/CrlMRBMhfGO1Q+S3p+tXaKAKXkv6frR5Len61dooArRRsrZPTFWaKKAP//Z',\n",
       " 'object_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-15/e35/24126550_307697142970254_2459485504198934528_n.jpg',\n",
       " 'owner': {'blocked_by_viewer': False,\n",
       "  'followed_by_viewer': False,\n",
       "  'full_name': 'Dominate',\n",
       "  'has_blocked_viewer': False,\n",
       "  'id': '497175667',\n",
       "  'is_private': False,\n",
       "  'is_unpublished': False,\n",
       "  'is_verified': False,\n",
       "  'profile_pic_url': 'https://scontent-lga3-1.cdninstagram.com/t51.2885-19/s150x150/21436105_461580107557246_6127532165056954368_a.jpg',\n",
       "  'requested_by_viewer': False,\n",
       "  'username': 'dominate_official'},\n",
       " 'scrape_ts': '2017-11-28 15:20:44',\n",
       " 'shortcode': 'BcCgqQWg_fR',\n",
       " 'should_log_client_event': False,\n",
       " 'taken_at_timestamp': 1511872749,\n",
       " 'the_fname': 'BcCgqQWg_fR.jpg',\n",
       " 'tracking_token': 'eyJ2ZXJzaW9uIjo1LCJwYXlsb2FkIjp7ImlzX2FuYWx5dGljc190cmFja2VkIjpmYWxzZSwidXVpZCI6ImVmMDM1NWYwNWVhMzQwMDc4MjViZTQxZDJiZTQ3ZTY2MTY1ODAzMTI1NDA4OTc1ODY3MyJ9LCJzaWduYXR1cmUiOiIifQ==',\n",
       " 'viewer_has_liked': False,\n",
       " 'viewer_has_saved': False,\n",
       " 'viewer_has_saved_to_collection': False}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_posts[\"BcCgqQWg_fR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No posts to update.\n"
     ]
    }
   ],
   "source": [
    "# update metadata for posts in storage\n",
    "\n",
    "update_frequency = 24 # hours\n",
    "\n",
    "codes_ready_for_update = []\n",
    "for code in the_posts:\n",
    "    latest_scrape = the_posts[code][\"activity\"][-1][\"scrape_ts\"]\n",
    "    time_since_latest_scrape = (datetime.now()-datetime.strptime(latest_scrape,\"%Y-%m-%d %H:%M:%S\")).total_seconds()\n",
    "    if time_since_latest_scrape > update_frequency * 3600:\n",
    "        codes_ready_for_update += [code]\n",
    "\n",
    "if len(codes_ready_for_update)>0 and input(\"Do you want to update \"+str(len(codes_ready_for_update))+\" posts? [Y/N] \") in \"Yy\":\n",
    "    ns = scrape_codes(codes_ready_for_update)\n",
    "    update_post_storage(ns)\n",
    "else:\n",
    "    print(\"No posts to update.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exctract comments and tags in comments for posts in the storage. Add as two attributes in the_posts.\n",
    "# Also update caption tags from caption\n",
    "for code in the_posts:\n",
    "    \n",
    "    the_posts[code][\"caption_tags\"] = extract_hashtags(the_posts[code].get(\"caption\",\"\"))\n",
    "    \n",
    "    comments = []\n",
    "    for a in the_posts[code][\"activity\"]:\n",
    "        for c in a[\"comments\"][\"nodes\"]:\n",
    "            comments += [c['text']]\n",
    "    comments = list(set(comments))\n",
    "    the_posts[code][\"comm_texts\"]=comments\n",
    "    the_posts[code][\"comm_tags\"]=extract_hashtags(\" \".join(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_.____________________.___.________.__.______.___\n",
      "__.._.____._________._.__________.________________\n",
      "_____.__._.______.________________________________\n",
      "_____________________._.._________.__.____________\n",
      "___._____________________________.____________.___\n",
      "______________________._______________.___________\n",
      "._______.__________.______________________________\n",
      "_________.___________.____________________.__._.__\n",
      "______"
     ]
    }
   ],
   "source": [
    "# download missing media objects\n",
    "cc = 0\n",
    "for code in the_posts:\n",
    "    cc += 1\n",
    "    if cc % 50 == 0: print()\n",
    "    download_object(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(data_path+\"/metadata.json\",\"w\")\n",
    "json.dump(the_posts,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate tags and labels into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells generate the following dataframes\n",
    "\n",
    "s_comm: all comments tags in all posts  \n",
    "s_cap: all caption tags in all posts  \n",
    "s_combined: all tags in all posts  \n",
    "s_labels: all labels (Google) in all posts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise \n",
    "all_labels = []\n",
    "comm_tags = []\n",
    "cap_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in the_posts:\n",
    "    cap_tags += the_posts[code].get(\"caption_tags\",[])\n",
    "    comm_tags += the_posts[code].get(\"comm_tags\",[]) #include tags found in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comment tags: 667\n",
      "Unique caption tags: 2560\n",
      "Tags both in comments and captions: 232\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique comment tags:\",len(set(comm_tags)))\n",
    "print(\"Unique caption tags:\",len(set(cap_tags)))\n",
    "print(\"Tags both in comments and captions:\",len(set(comm_tags).intersection(set(cap_tags))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_comm = pd.DataFrame(Counter(comm_tags).most_common(100)[1:],columns=[\"tags\",\"freq\"])\n",
    "s_comm[\"type\"]=\"comment\"\n",
    "s_cap = pd.DataFrame(Counter(cap_tags).most_common(100)[1:],columns=[\"tags\",\"freq\"])\n",
    "s_cap[\"type\"]=\"caption\"\n",
    "s_combined = s_comm.append(s_cap)\n",
    "s_combined.index = range(0,len(s_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in the_posts:\n",
    "    if \"labels\" in the_posts[code]:\n",
    "        all_labels += list(map(lambda x:x[\"description\"], the_posts[code][\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_labels = pd.DataFrame(Counter(all_labels).most_common(40),columns=[\"labels\",\"freq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_comm.to_csv(data_path+\"/s_comm.csv\")\n",
    "s_cap.to_csv(data_path+\"/s_cap.csv\")\n",
    "s_combined.to_csv(data_path+\"/s_combined.csv\")\n",
    "s_labels.to_csv(data_path+\"/s_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HTML for the Photo Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_total_likes(p):\n",
    "    likes = 0\n",
    "    for u in p['activity']:\n",
    "        if u[\"video_views\"] == \"not_a_video\":\n",
    "            likes += u[\"likes\"][\"count\"]\n",
    "        else:\n",
    "            likes += u[\"video_views\"] \n",
    "    return likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if deets[\"display\"][\"selected_labels\"]==[]:\n",
    "    selected_labels = set(all_labels)\n",
    "else:\n",
    "    selected_labels = set(deets[\"display\"][\"selected_labels\"])\n",
    "    \n",
    "banned_labels = set(deets[\"display\"][\"banned_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if deets[\"display\"][\"selected_tags\"]==[]:\n",
    "    selected_tags = set(cap_tags+comm_tags)\n",
    "else:\n",
    "    selected_tags = set(deets[\"display\"][\"selected_tags\"])\n",
    "    \n",
    "banned_tags = set(deets[\"display\"][\"banned_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(the_posts),\"posts in total\")\n",
    "the_code = ''\n",
    "\n",
    "cc = 1\n",
    "the_size = 150\n",
    "include_this = True\n",
    "\n",
    "\n",
    "for code in the_posts:\n",
    "    include_this = True\n",
    "    if cc > 50000: break\n",
    "        \n",
    "    ##############################################################################\n",
    "    ## Start of the section where photos/videos are selected to be included or not\n",
    "    if 'labels' in the_posts[code]:\n",
    "        photo_labels = set(map(lambda x:x[\"description\"], the_posts[code][\"labels\"]))\n",
    "    else:\n",
    "        photo_labels = set()\n",
    "    \n",
    "    if  not the_posts[code][\"is_video\"] and len(all_labels)>0:\n",
    "        if len(photo_labels.intersection(selected_labels))==0 or \\\n",
    "        len(photo_labels.intersection(banned_labels))>0: \n",
    "            include_this = False\n",
    "\n",
    "    photo_tags =  set(the_posts[code][\"caption_tags\"]+the_posts[code][\"caption_tags\"])\n",
    "    if len(cap_tags+comm_tags)>0:\n",
    "        if len(photo_tags.intersection(selected_tags))==0 or \\\n",
    "        len(photo_tags.intersection(banned_tags))>0:\n",
    "            include_this = False\n",
    "\n",
    "    if get_total_likes(the_posts[code])<deets[\"display\"][\"min_likes\"] or \\\n",
    "    get_total_likes(the_posts[code])>deets[\"display\"][\"max_likes\"]:\n",
    "        include_this = False\n",
    "    \n",
    "    if the_posts[code][\"is_ad\"]: include_this = deets[\"display\"][\"include_ads\"]==\"yes\" and include_this\n",
    "    \n",
    "    if deets[\"display\"][\"include_videos\"]==\"none\" and the_posts[code][\"is_video\"]: include_this = False\n",
    "    if deets[\"display\"][\"include_photos\"]==\"none\" and not the_posts[code][\"is_video\"]: include_this = False    \n",
    "    \n",
    "    # the conditions below can turn back a \"False\" generated in the previous statements\n",
    "    if len(photo_labels)==0 and not the_posts[code][\"is_video\"]: include_this = True\n",
    "    if len(photo_tags)==0: include_this = True\n",
    "    \n",
    "    if deets[\"display\"][\"include_videos\"]==\"all\" and the_posts[code][\"is_video\"]: include_this = True\n",
    "    if deets[\"display\"][\"include_photos\"]==\"all\" and not the_posts[code][\"is_video\"]: include_this = True\n",
    "    ##################################################################################\n",
    "    ## End of the section for selecting photos/videos\n",
    "    ##################################################################################\n",
    "    \n",
    "    \n",
    "    if include_this:\n",
    "        cc += 1\n",
    "        if not the_posts[code][\"is_video\"]:\n",
    "        \n",
    "            the_code += '<div class=\"imgWrap\" width='+str(the_size)+' height='+str(the_size)+'>'\n",
    "            the_code += '<a href=\"https://www.instagram.com/p/'+code+'\" target=\"_blank\">'\n",
    "            the_code += '<img class=\"centered-and-cropped\" src=\"../media/'+the_posts[code]['the_fname']\n",
    "            the_code += '\" width='+str(the_size)+' height='+str(the_size)+' alt=\"\">'\n",
    "            the_code += '<p class=\"imgDescription\">'+clstr(the_posts[code].get(\"caption\",\"\")[:300])+'</p>'\n",
    "            the_code += '</a>'\n",
    "            the_code += '</div>&nbsp;'\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            the_code += '<a href=\"https://www.instagram.com/p/'+code+'\" target=\"_blank\">'\n",
    "            the_code += '<video height=\"'+str(the_size)\n",
    "            the_code += '\" onmouseover=\"this.play();\" onmouseout=\"this.pause();\">'\n",
    "            the_code += '<source src=\"../media/'+the_posts[code]['the_fname']+'\" type=\"video/mp4\">'\n",
    "            the_code += '</video>&nbsp;'\n",
    "            the_code += '</a>'\n",
    "\n",
    "print(\"Ready to display\",cc-1,\"objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(data_path+\"/\"+the_item+\"_grid.html\",\"w\")\n",
    "f.write('<html><head><link rel=\"stylesheet\" href=\"../insta.css\"></head><body>')\n",
    "f.write(the_code)\n",
    "f.write(\"</body></html>\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
