{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key\n",
    "- (1, 2,...4) when we see this in front of after a topic, it indicates the importance of learning this topic with 1 being the lowest, and 4 a must know, internalize, and make part of my everyday life in some way. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0- Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Probability\n",
    "- Combinatorics\n",
    "    - combinations (choose) $\\left(\\begin{array}{c}n\\\\k\\end{array}\\right)$ (Def: )\n",
    "    - permutations\n",
    "    - Factorials $n!$\n",
    "    - (counting problems) find and practice. \n",
    "        - definitional - calculate permutations. \n",
    "            1. identify as perumation problem\n",
    "            2. recall and use formula appropriately\n",
    "        - composite - \n",
    "            1. hard counting problems (number of poker hands)\n",
    "            2. these require careful, clever, attentive calculating.\n",
    "            3. can be very hard. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distributions I:\n",
    "    - <p style=\"color:red\">Score= 4- understand the distinction and role of parameters and outcomes/random variables in the functional form of a distribution.</p> \n",
    "        - e.g., to carefully distinguish $\\bar X = \\frac{1}{n} \\sum_{i=1}^n X_i from \\bar x = \\frac{1}{n} \\sum_{i=1}^n x_i  from  f(\\bar X = \\bar x)/Pr(\\bar X = \\bar x)$\n",
    "            - Notation: $X \\sim Poisson(\\lambda) $ (\"X is distributed according to a poisson distribution\")is shorthand for $Pr(X=x) = \\frac{\\lambda^x e^{- \\lambda}}{x!}$ = Poisson Math (4)\n",
    "            - $\\bar X$ is a R.V. distribution in some way. (4)\n",
    "            - $\\bar x$ is an outcome -- sample from a distribution. (4)\n",
    "    - <p style=\"color:red\">Score= 4- being able to evalue/interpret/use calculated values... areas or heights</p>\n",
    "    - parameter (specifying the instance in question. usually greek characters)\n",
    "    - outcomes associated with random vaiables (usually $x$ but not always)\n",
    "    - know the definition and thus be able to work with summation notation this is a big part of statistical mathematics (4)\n",
    "    \n",
    "    - know the definition and be able to work with integration notation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distributions II\n",
    "- Problems: ex dist, ex calculation w/dist\n",
    "    - define a distribution by its math. able to write math formulas. \n",
    "    3. evaluated values.. areas or heights. \n",
    "        \n",
    "        - pmf heights $Pr(X=x)$\n",
    "        - pdf heights $f(X=x)$ relative freq not a probability.\n",
    "        - pdf areas $Pr(a < X < b) = \\int_a^b f(X=x) dx $ areas give probabilities\n",
    "            - cdf: $Pr(-\\infty < X ,x) = \\int_{infty}^x f(X=x') dx'$\n",
    "        - (Questions: ...)\n",
    "            - identify parameters in the math. \n",
    "            - identify outcomes\n",
    "\n",
    "            - Suppose that large majority of people in NYC are not from NYC. What's the probability that 10 out of 13 randomly selected people in NYC are not from NYC\n",
    "                - Possible answer: Calculate $Pr(X=10) for X \\sim Binomial(n=13, p=.9)$\n",
    "                    - return calculation: \n",
    "            - At a mall, what's the probabilyt that 10 peoople enter your store in the next 15 minutes? \n",
    "                - Possible answer....?\n",
    "            - Is it more likely that someone in the population is 6 feet tall or 5 feet tall?\n",
    "            - what's the probability that the next person you see is 5'5\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distributions III\n",
    "    - pdf (continuous give \"relative frequencies\") (3)\n",
    "        - $X \\sim normal(E[X]=mu, Var[X] = \\sigma^2)$ (4)\n",
    "            - This is a 10. know this. internalize it. \n",
    "            - assume CLT hold (n is large) score=(4)\n",
    "            - $\\bar X \\sim N\\left(E[\\bar X] = \\mu_X, Var[\\bar X] = \\frac{\\sigma_X^2}{n}\\right)$\n",
    "            - $\\bar X$ is normally distributed if $X_i$ 's are normally distributed\n",
    "            - if data fails to be normlally distributed then $\\bar X$ will be approximately normally distributed, with increasing accuracy of approximation as sample size is larger.\n",
    "            - $Var(\\bar X)$ - proved this\n",
    "            - $E[\\bar X]$ - proved this\n",
    "            - These are a 10 below. \n",
    "                1. $E[Y]$ - center or mean or location of a dist. \n",
    "                2. $Var(Y)$ - variance or spread or volitility is given by distribution\n",
    "           \n",
    "            - Standardization: $\\frac{X-E[X]}{SD(X)}$ (3.5)\n",
    "                - This is a 9.5. know this. internalize it. \n",
    "                - $Y \\sim f(E[Y], SD[Y])$ then $Y^* = \\frac{Y-E[Y]}{SD(Y)} \\sim f^*(E[\\frac{Y-E[Y]}{SD(Y)}] =0, SD[\\frac{Y-E[Y]}{SD(Y)}] =1)$\n",
    "            - $f^*$ and $f$ have same \"curvature\" -- but have different scale/height and different loc. \n",
    "            - when $\\bar X$ is normally (or approximately normally) distributed, then:\n",
    "                - $\\frac{\\bar X - \\mu_X}{\\frac{\\sigma_X}{\\sqrt n}} \\overset{\\tiny approx}{\\sim} N(0,1) $\n",
    "\n",
    "            - $E[\\frac{\\bar X - \\mu_X}{\\frac{\\sigma_X}{\\sqrt{n}}}] = 0$\n",
    "            - $Var(\\frac{\\bar X - \\mu_X}{\\frac{\\sigma_X}{\\sqrt{n}}}) =1$\n",
    "             \n",
    "        - $X \\sim t_{df}$ (2) -- (when we plug in $s$ for $\\sigma_X$ in the above standarized normal, we get the t-distribution.)\n",
    "            - df (degrees of freedom) is single param of t-dist. which controls heaviness of the tails.\n",
    "            - t is centered on 0\n",
    "            - the t has no free parameter defining it's spread\n",
    "            -\"standardized\" the random variable \n",
    "            # $$\\frac{\\bar X-\\mu_X}{\\sqrt{\\frac{\\frac{\\sum_i=1^n(X_i - \\bar X)^2}{n-1}}{n}}} \\sim t_{n-1} \\quad(1) $$\n",
    "                - question: suppose you have a sample of size 4 from a population with mean $\\mu_X =10$. What's the probability that $\\bar X < 9.9 (i.e. Pr(\\bar X=\\bar x < 9.9)$\n",
    "                - Lauren: assume $X_i \\overset{\\tiny i.i.d}{\\sim} N(\\mu_X, \\sigma_X)$, for $i = 1, \\cdots, n, \\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i$\n",
    "                - go see \"such and such notebook for worked problem. \n",
    "                - 2nd Question: (Hypothesis testing)\n",
    "                    - choose population, shoose sample size (vary different options)\n",
    "                    - create a large number of repeated samples\n",
    "                    - calculate t-statistics using $\\mu_x$ and $s$\n",
    "                    - calc. proportion of these that fall in the 5% of the tails of a t-dist. \n",
    "                    - do the above t-stat calcs using an incorrect population mean. \n",
    "                        - now what proportion fall in the 5% of the teails of t-dist.\n",
    "        - $X \\sim Gamma(\\alpha, \\beta)$\n",
    "\n",
    "        - another dist????\n",
    "        - another dist???\n",
    "    \n",
    "    <br>- pmf (discrete)\n",
    "        - $X \\sim Poisson(E[X]=\\lambda, Var(X)=\\lambda)$\n",
    "        - $X \\sim Binomial(E[X]=np, Var(X)=n*p*(1-p))$\n",
    "            - $X \\sim Binomial(n,p)$\n",
    "        - $X \\sim Exponential$\n",
    "        - $X \\sim Geometric$\n",
    "        - $X \\sim Negative Binomial$\n",
    "\n",
    "- cdf\n",
    "    - parameters\n",
    "        - $E[X]$\n",
    "        - $Var[X]$\n",
    "\n",
    "- Sampling \n",
    "    - Random Variables ($X_i$ big x\")\n",
    "    - outcomes ($x_i$ -- \"little x\") are actualized from RVs\n",
    "    - i.i.d.\n",
    "    - confounding\n",
    "    - randomization\n",
    "    -observational studies\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardization \n",
    "- standard deviation is a nice \"intrinsic\" scale on which the data can be said to exist. \n",
    "- e.g., N(10, 4) w might say the standard step/scale is 4 units in whatever units these numbers are associated with in the real world. in this example center is 10 and 1st std dev. is 14, -1 std is 6, etc. \n",
    "- when we \"standardize\", $\\frac{x_1 -\\mu_X}{\\sigma_X}$, we are turning the step size scale to 1. so every distribuionn/feature we do this to can be said to be \"commonly/similarly\" scaled.\n",
    "- '\n",
    "- they all live in the sam region (in absolute terms) of the number line now -- i.e., centered at zero, spread from about -2 to 2 (which is accurate as long as the origianal distributin was approximately normal.  often this standardiszation serves to center things at 0. \n",
    "1. random variable rescaling\n",
    "    - converting to standard normal from any other normal\n",
    "    - the context of the t-distribution\n",
    "    - we have that $f(x_1)/f(x_2)$ this ratio will remain unchanged after scaling -- i.e., it will be the same as $f(\\frac{x_1 - loc}{scale})/f(\\frac{x_2 -loc}{scale})$\n",
    "        - the x-axis is getting revalued, but the relative shape of the pdf remains unchanged -- the height will change to auto ensure area 1 under the curve... my string example pulled at the ends. I take a string a pull at the top of the curve and the ends get closer towards the center. and the center gets higher. same idea with standardizing the spread. \n",
    "2. feature standardization\n",
    "    - features on different scales. -- having different absolute values with respect to their intrinsic scales. (i.e. different variances in absolute terms) \n",
    "    - the \"intrinsic units\" of a feature are measured in standard deviations \n",
    "    - e.g., if feature A has a standard dev. of 5 \n",
    "    - and feature B has a standard deviation of 40\n",
    "    - the mathematical behavior of these features will be quite different in the context of predictive modeling. \n",
    "    - predictive models often have a bias agains more highly varying features -- they attribute \"less effect\" to these features beause in absolute terms these features may vary quite a bit (absoute terms) before an impact of the change registers in the model. this, the effect per absolute change in feature value is \"small.\"\n",
    "    - if 2 features had the same effect along their intrinsic scales, then the effect of the feature having more variance will be viewed as \"less\" influencial on the outcome by the model. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference (the inverse problem)\n",
    "- given a distribution instance, we can do things like:\n",
    "    - calculate various forms of probabilities of outcomes from this distribution (i.e., actualizations of random variables distributed according to this distribution)\n",
    "    - provide characterizations of the distribution/populatin such that $E[X]$ or $Var(X)$ = $[E[X] \\overset{\\tiny discrete}{=} \\sum_{x}x Pr(X = x) \\overset{\\tiny continuous}{=} \\int_{\\infty}^\\infty xf(X=x) dx$ \n",
    "    - or $Var(X) = E[(X-E[X])^2] \\overset{\\tiny discrete}{=} \\sum_x (x - E[X])^2 Pr(X=x) dx$\n",
    "    - these are sumation  or integral definitions based on pmf $Pr(X=x)$ or pdf $f(X=x)$ (which are mathematical representations of a population).\n",
    "    - this is called the **forward problem**\n",
    "    - we do things with math -- we use mathematical specifications (pmf/pdf) to calculate various properties of the system this sprecified. \n",
    "    - e.g., 52 deck given. task: calculate probabilities in this context. \n",
    "    - we have the world speicified and we ask questions about it. \n",
    "    \n",
    "- all of the above, is NOT the inverse problem ( or the \"inference\" problem). The inference problems is the following.\n",
    "\n",
    "\n",
    "1. We're in the world and can see some things about it.\n",
    "2. We use those things to make general statements about the nature of the world. \n",
    "\n",
    "\n",
    "1. We can sample from unspeicified distributions\n",
    "2. We can use thos samples to make some characterizations of the underlying distributions. \n",
    "\n",
    "\n",
    "- *Uncertainty Assessment*\n",
    "    - central limit theorem\n",
    "    $$X_i \\overset{i.i.d.}{\\sim} f(E[X_i]  = \\mu_X, Var(Xi) = \\sigma_X^2), i=1, \\cdots, n$$\n",
    "    $$\\bar X_n \\overset{\\tiny approx}{\\sim}N(E[\\bar X] = \\mu_X, Var(\\bar X) = \\sigma^2_X/n = \\sigma_{\\bar X}^2) $$ \n",
    "        - $E[\\bar X]$ and $Var(\\bar X)$ are mathematical properties we have proved:\n",
    "            - problem: see if you can re-reprove. \n",
    "              \n",
    "    - Confidence intervals \n",
    "        - Don't forget to see the t distributiion stuff above\n",
    "    - bootstrapped confidence intervals\n",
    "    \n",
    "- *Best Guess* methodology\n",
    "\n",
    "    - Method of moments: (tie samples to parameters -- use sample statistics to estimate populatin parameters)\n",
    "        - $E[\\bar X] = \\mu_X (Var(\\bar X) = \\sigma_X^2/n)$ which is our rational for $\\bar x$ being a \"good guess\" for $\\mu_X$ (if $n$ is \"large\" then $\\bar x$ is very close to $\\mu_X$)\n",
    "        - $E[X^2] = \\sigma_X^2$ so again $s^2$ is a \"good guess\" for $\\sigma^2$ -- we just use this as an \"on the fly\" \"plug-in\" estimate for $\\sigma_X^2$ in the context of a t-distributions based analysis. \n",
    "\n",
    "- Maximum Likelihood Estimation\n",
    "    - assume a distributional family (you may re-try on multiple distiubiotns families if you wish)\n",
    "    - choose the parameters of the distributions hich make the data as \"likely\" as possible. \n",
    "    - $g([X_1, X_2, \\cdots, X_n]) = [x_1, x_2, \\cdots, x_n] \\overset{\\tiny i.i.d.}{=} \\prod_{i=1}^n f(X_i=x_i)$ (don't forget the log trick! for computational purposes)\n",
    "    - above, $g$ is a distribution over a vector (a joint distribution)\n",
    "    - above, $f$ is a distribtution for a single random variable (a marginal distribution)\n",
    "    - if $X_i \\overset{i.i.d.}{\\sim} f$ then the above equality holds.\n",
    "    - i.e., if the vector above is a \"random sample\"\n",
    "    - This DOES NOT HOLD if the vector of the X's is actually an individual (high dimension) data point -=- i.e., if it's multiple (dependent) measures on the same individual. (in this case we need to go to the multivariate pdf/pmf defining the relativefrequencies over the vctors, i.e., the vector is a single data point with a relative frequency of occuring)\n",
    "\n",
    "\n",
    "#### problems: See workbook Inference-Problems\n",
    "\n",
    "1. construct a confidence interval (x-bar --> confidence for the population mean)\n",
    "2. compare a bootstrap confidence interval to the above confidence interval \n",
    "3. provide an estimate (both MLE and Mom) of the distribuion which generated a sample. \n",
    "    - first use the \"right\" distribution, figure out which dist the sample came from. \n",
    "    - use a \"wrong\" distribution\n",
    "    - compare the truth with the \"truth estimate, with the \"wrong\" estimate.\n",
    "4. compete these and tell me which distributional estimates is better?\n",
    "    \n",
    "\n",
    "### Statistics is the enterprise of making gueses on data, and quantifying the uncertainty of these gueses to characterize ones risk of choosing a path. \n",
    "\n",
    "#### -- boils down to these 2 ideas. collect data to inform decision --> assess uncertainty in the data with respect to that decision. \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Quiz:\n",
    "- take a sample of size small n from a normal distribution. \n",
    "- after taking sample, forget $\\sigma_x$\n",
    "- calculate the probability of the sample standaridzed average lying between some range.\n",
    "\n",
    "- $\\frac{\\bar x -\\mu_X}{s}$ -- you may assume $\\mu_X$ is known for this calculatin -- but not $\\sigma_X$\n",
    "\n",
    "- Simulate this outcome repeatedly, and see if in fact you achieve your theoretical operating characteristics. \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "- Pick a range from low to high\n",
    "    - f($X = x)$ where 0 <= $X_i <=100 for n=10\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a bunch of random variables from a normal dist. \n",
    "rvs_list = stats.norm.rvs(size=1000,loc=3, scale=45)\n",
    "#grab 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz 3\n",
    "- write a function which takes a sample and returns the transformed sample that does this to each outcome in the sample. \n",
    "\n",
    "- $\\frac{x_i - \\bar x}{x}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimation\n",
    "    - MLE/MoM -- best guesses\n",
    "        - MLE is try parameter values and choose the best based on likelihood\n",
    "        - MoM is tie a test statistic to a population parameter. \n",
    "    - Confidence intervals -- good guess WITH uncertainty estimate\n",
    "\n",
    "- Confidence Intervals\n",
    "    - Null Hypothesis NOT required, but can be tested and this is equivalent to hypothesis testing.\n",
    "    - estimate and qualitative/quantitive feel for the uncertainty of the estimate\n",
    "    - interpretation: uncertainty is characterized in terms of the estimation procedure. \n",
    "    - \"mean is either in or not -- a binary true or false\"\n",
    "\n",
    "- bootstrapping\n",
    "    - if you can't do CLT-based CI\n",
    "    - if you don't have theoretical CI results for something, e.g., $s$\n",
    "    - use the sample as though it was a distribution\n",
    "- Hypothesis testing\n",
    "    - H_0\n",
    "    - is for rejecting status quoue\n",
    "    - critical cutoffs Z_Alpha\n",
    "    - p-values vs alpha\n",
    "        - be careful... p-values must be interpreted carefully\n",
    "        - null hypothesis does not have a probability of being true: it either is or isn't\n",
    "    - confidence Intervals\n",
    "    - $\\alpha$ Type I\n",
    "        - set your risk tolerance\n",
    "    - $\\Beta$ Type II\n",
    "        - H_A\n",
    "        - \"effect size\"\n",
    "        - Power analysis\n",
    "        - set your success risk profile\n",
    "- CLT versus t\n",
    "    - sample size is the driver here\n",
    "    - assumes:\n",
    "        - sample comes from normal\n",
    "        - and i.i.d\n",
    "    - z_alpha... T_df, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
