{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are Multiple working example exercises here: \n",
    "\n",
    "### Key Points:\n",
    "#### - What does standardizing data do?\n",
    "#### - Are there any changes to our outcome when we standardize our data? center mu to 0 and spread to 1 std. dev. ? other than the data is centered etc. or do the properties of the distribution now change in some way? \n",
    "#### - How does the law of large numbers (LOLN) and CLT apply. \n",
    "    - we will see that X_bar when LOLN and CLT apply is a good estimate of mu\n",
    "    - we will see as the variance/spread narrows our confidence in the above statement increases. \n",
    "    \n",
    "## Further work to demonstrate CLT visually:\n",
    "    - Bokeh of CLT\n",
    "    - Pulldown for choosing distributions:\n",
    "    - Standardize the sample:\n",
    "    - Demonstrate CLT for Different n\n",
    "    - Add a vertical line for where mu actually is. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise One:\n",
    "- take a random sample\n",
    "- \"standardize it\" (center by $\\bar x$ and scale by $s$\n",
    "- call $x_i*$'s the new samples\n",
    "- calculate $\\bar x*$ and $s*$\n",
    "- do this a few times, maybe with some different distributional settings\n",
    "- what do we find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85144658896594039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.cdf(1.1, df=10, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(21-10)/10 # (x-loc)/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85144658896594039"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.cdf(21, df=10, loc=10, scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samp1 x_bar and std 3.27632603724 0.333081435075\n",
      "samp1 standardized x_bar and std 4.29286236188e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "samp1 = stats.norm.rvs(size = 15, loc=3, scale=.5)\n",
    "x_bar = samp1.mean()\n",
    "s_samp1 = samp1.std(ddof=1)\n",
    "samp1_standardized = (samp1 -x_bar)\n",
    "samp1_standardized = samp1_standardized/(s_samp1)\n",
    "print(\"samp1 x_bar and std\", x_bar, s_samp1)\n",
    "print(\"samp1 standardized x_bar and std\", samp1_standardized.mean(), samp1_standardized.std(ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.26631185  3.29218994  2.68492954  2.64450756  3.56444005  3.4777615\n",
      "  3.32421675  3.65321498  3.67251711  3.54706074  3.2025009   2.80758415\n",
      "  3.50211962  3.37205299  3.13348288]\n",
      "[-0.03006528  0.0476277  -1.77553126 -1.8968889   0.8649957   0.6047634\n",
      "  0.14378081  1.13152191  1.18947211  0.81281835 -0.2216429  -1.40728915\n",
      "  0.67789304  0.28739803 -0.42885354]\n"
     ]
    }
   ],
   "source": [
    "print(samp1)\n",
    "print(samp1_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_samp(my_rvs):\n",
    "    x_bar = my_rvs.mean()\n",
    "    s_samp1 = my_rvs.std(ddof=1)\n",
    "    samp1_standardized  = (my_rvs -x_bar)\n",
    "#     samp1_standardized = samp1_standardized/(s_samp1/np.sqrt(len(my_rvs)))\n",
    "    samp1_standardized = samp1_standardized/(s_samp1)\n",
    "    print(\"samp1 x_bar and std\", x_bar, s_samp1)\n",
    "    print(\"samp1 standardized x_bar and std\", samp1_standardized.mean(), samp1_standardized.std(ddof=1))\n",
    "    return ((my_rvs, samp1_standardized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samp1 x_bar and std 1.00920539122 5.37883147583\n",
      "samp1 standardized x_bar and std -7.40148683083e-18 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ -1.25944018,   5.29876641,  -3.64912393,  -1.38972121,\n",
       "         -4.17135026,   3.49237373,  -3.0411194 ,   0.07024007,\n",
       "         -0.95026054,  -3.98845121,  -5.93101475,  13.74127285,\n",
       "          5.35400739,   6.13299168,   5.42891022]),\n",
       " array([-0.42177294,  0.79748939, -0.86604857, -0.44599401, -0.96313775,\n",
       "         0.46165572, -0.75301203, -0.17456679, -0.36429212, -0.92913426,\n",
       "        -1.29028399,  2.36706941,  0.80775946,  0.95258353,  0.82168494]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs2 = stats.norm.rvs(size = 15, loc=3, scale=7)\n",
    "calc_samp(rvs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Two: \n",
    "\n",
    "don't standardize by $\\bar x$ and $s$\n",
    "instead, standize by $\\mu$ and $\\sigma$\n",
    "\n",
    "e.g., `stats.gamma(a=1, scale=1/2).mean()` and `stats.gamma(a=1, scale=1/2).std()`\n",
    "\n",
    "- do this a few times---calculate the $\\bar x*$ and $s*$ for your standarized sample\n",
    "- descibe what your'e seeing (hint: from what distribution are these things coming from?) \n",
    "- do this a very large number of times such that you have a large collection of $\\bar x*$'s and $s*$'s.\n",
    "- calculate the mean and standard deviation of the $\\bar x*$'s \n",
    "- calculate the mean and standard deviation of the original $\\bar x*$'s \n",
    "\n",
    "- hint: $\\sigma/\\sqrt{n}$\n",
    "\n",
    "- super hing: i suggest large enough sample size for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get my data in this cell.\n",
    "\n",
    "location = 7\n",
    "my_scale = 13\n",
    "n_samp = 150\n",
    "repeat_draws = 100000\n",
    "samp_list = []\n",
    "\n",
    "dist_mu = stats.expon(loc= location, scale=my_scale).mean()\n",
    "dist_std = stats.expon(loc= location, scale=my_scale).std()\n",
    "\n",
    "for _ in range(repeat_draws):\n",
    "    samp_list.append(stats.expon.rvs(loc= location, scale=my_scale, size=n_samp))\n",
    "\n",
    "samp_np = np.array(samp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_mu 20.0 and dist_std 13.0\n",
      "X_bar_pre_standardized 20.00510594053958\n",
      "X_bar_standardized 0.0003927646568911125.\n",
      "\n",
      "S pre-standardized calc by mean of s list 12.916750593511331\n",
      "S_standardized calc by mean of s list 0.9935961995008716\n"
     ]
    }
   ],
   "source": [
    "# Work with the data to find X_bar and S^2 etc. and compare to population mu and sigma\n",
    "## this is a clean refactored version of the scratch from below. \n",
    "\n",
    "samp_std_np = (samp_np-dist_mu)/dist_std\n",
    "print('dist_mu {} and dist_std {}'.format(dist_mu, dist_std))\n",
    "print('X_bar_pre_standardized {}'.format(samp_np.mean()))\n",
    "print('X_bar_standardized {}.'.format(samp_std_np.mean()))\n",
    "\n",
    "print(\"\")\n",
    "S_pre_std = np.std(samp_np, axis=1, ddof=1)\n",
    "S_standardized = np.std(samp_std_np, axis=1, ddof=1)\n",
    "print('S pre-standardized calc by mean of s list {}'.format(S_pre_std.mean()))\n",
    "print('S_standardized calc by mean of s list {}'.format(S_standardized.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_mu 20.0 and dist_std 13.0\n",
      "X_bar_standardized -0.0001366204089734732.\n",
      "X_bar_pre_std 19.99822393468335\n",
      "\n",
      "Interesting, I get the same results whether I take the mean of the entire np.array or       calculate each X_i mean, add, and divide by n.\n",
      "\n",
      "exmple pre_standardized mu calc entire list, 19.998223934683338 and     pre standarized mu calc using each X_i 19.99822393468335\n",
      "\n",
      "S_standardized calc by mean of Var[X_bar]-s 0.9852650087541602\n",
      "S_standardized with sum and divide by n 0.9852650087541602\n",
      "\n",
      "\n",
      "wrong -- S_standardized np.std on all data points 0.9998100424842569\n",
      "wrong -- S_standardized with divide by sqrt n 311.56815265288833\n"
     ]
    }
   ],
   "source": [
    "## below code is some experiments and testing I did before I refactored the code\n",
    "## into the above simplified version. \n",
    "\n",
    "samp_std_np = (samp_np-dist_mu)/dist_std\n",
    "# print (samp_np)\n",
    "# print(samp_std_np)\n",
    "\n",
    "\n",
    "X_bar_standardized = samp_std_np.mean()\n",
    "X_bar_pre_std = np.mean(samp_np, axis=1)\n",
    "S_standardized = np.std(samp_std_np, axis=1)\n",
    "S_pre_std = np.std(samp_np, axis=1)\n",
    "\n",
    "print('dist_mu {} and dist_std {}'.format(dist_mu, dist_std))\n",
    "print('X_bar_standardized {}.'.format(X_bar_standardized))\n",
    "\n",
    "print('X_bar_pre_std {}'.format(X_bar_pre_std.mean()))\n",
    "\n",
    "print(\"\")\n",
    "print('Interesting, I get the same results whether I take the mean of the entire np.array or \\\n",
    "      calculate each X_i mean, add, and divide by n.')\n",
    "print(\"\")\n",
    "print(\"exmple pre_standardized mu calc entire list, {} and \\\n",
    "    pre standarized mu calc using each X_i {}\"\\\n",
    "      .format(samp_np.mean(), X_bar_pre_std.mean()))\n",
    "print(\"\")\n",
    "\n",
    "print('S_standardized calc by mean of Var[X_bar]-s {}'.format(S_standardized.mean()))\n",
    "print('S_standardized with sum and divide by n {}'.format(S_standardized.sum()/repeat_draws))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print('wrong -- S_standardized np.std on all data points {}'.format(samp_std_np.std(ddof=1)))\n",
    "\n",
    "print('wrong -- S_standardized with divide by sqrt n {}'.format(S_standardized.sum()/np.sqrt(repeat_draws)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
